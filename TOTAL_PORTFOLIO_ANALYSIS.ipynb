{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d740ad",
   "metadata": {},
   "source": [
    "<h1 style = \"text-decoration: underline\">TOTAL PORTFOLIO ANALYSIS</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14920fa",
   "metadata": {},
   "source": [
    "<h2 style = \"text-decoration: underline\">Importações</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59935f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as web\n",
    "from pandas_datareader import data as pdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "        #In SciPy the kurtosis function is actually computing excess kurtosis (greater than 0 suggests non-normality). \n",
    "        #If you wanted to calculate the true sample kurtosis, you would actually need to add 3 to the result. \n",
    "        #For most cases, you're going to be interested in excess kurtosis anyways, so this functionality \n",
    "        #is fine as long as you are aware of it. \n",
    "        #In finance, high excess kurtosis is an indication of high risk. \n",
    "        #When large movements in returns happen often, this can be a very bad thing for your portfolio if it moves in \n",
    "        #the wrong direction. High kurtosis distributions are said to have \"thick tails\", which means that outliers, \n",
    "        #such as extreme negative and positive returns, are more common.\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as sco\n",
    "import seaborn as sns\n",
    "import win32com.client\n",
    "from openpyxl import load_workbook\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a507ebd",
   "metadata": {},
   "source": [
    "<h2 style = \"text-decoration: underline\">Obter dados do Portfolio</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8000f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pimeiramente abra a planilha Portfolio_Acoes e inira os ativos para importar do Yahoo Finance - Planilha \"990 Portfolio_Acoes\"\n",
    "#Ações brasileiras devem ser inseridas com .SA após o símbolo\n",
    "df = pd.read_excel('990 Portfolio_Acoes.xlsx')\n",
    "ativos = df['AÇÕES'].tolist()\n",
    "num_acoes = len(ativos)\n",
    "num_acoes = int(num_acoes)\n",
    "\n",
    "print(ativos, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56267e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importar do Yahoo Finance\n",
    "data_final = dt.datetime.today()\n",
    "data_inicial = data_final-dt.timedelta(days=1825)\n",
    "\n",
    "ls_key = 'Adj Close'\n",
    "start = data_inicial\n",
    "end = data_final   \n",
    "f = web.DataReader(ativos, 'yahoo',start,end)\n",
    "\n",
    "dados = f[ls_key]\n",
    "dados_df = pd.DataFrame(dados).dropna()\n",
    "\n",
    "dados_df.to_csv('999 Dados.csv', sep = ';', index = True, header = True)\n",
    "dados = pd.read_csv('999 Dados.csv', sep = ';', parse_dates=['Date'])\n",
    "\n",
    "print (dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abra a planilha Portfolio_Fundos e insira os Fundos ou outros Ativos para importar de outras fontes, via planilha Excel (Criar duas planilhas, uma para obter os dados\n",
    "#da fonte, outra para padronizar para importação, as datas são as obtidas acima, a coluna com os preços é a segunda [1], etc.)\n",
    "\n",
    "##Inserir os Fundos para importar para o Python - Planilha \"990 Portfolio_Fundos\"\n",
    "\n",
    "df = pd.read_excel('990 Portfolio_Fundos.xlsx')\n",
    "fundos = df['FUNDOS'].tolist()\n",
    "num_fundos = len(fundos)\n",
    "num_fundos = int(num_fundos)\n",
    "\n",
    "n = 0\n",
    "for x in range(num_fundos): \n",
    "    abrir = fundos[n]\n",
    "    xl = win32com.client.DispatchEx(\"Excel.Application\")\n",
    "    wb2 = xl.workbooks.open(r'...\\999 Dados.csv')\n",
    "    time.sleep(10)\n",
    "    wb1 = xl.workbooks.open(r'...\\990 '+ abrir +'.xlsx') \n",
    "                                                                                            #planilha para obter dados\n",
    "    time.sleep(25)\n",
    "    wb = xl.workbooks.open(r'...\\990 '+ abrir +\n",
    "                           ' - Dados Python.xlsx') #planilha padronizada para importação pelo Python\n",
    "    time.sleep(25)\n",
    "    wb.Close(True)\n",
    "    wb1.Close(True)\n",
    "    wb2.Close(True)\n",
    "    time.sleep(10)\n",
    "    read_file = pd.read_excel (r'...\\990 '+ abrir +\n",
    "                               ' - Dados Python.xlsx', index_col = 'Date')\n",
    "    read_file.to_csv (r'...\\999 '+ abrir +\n",
    "                      ' - Dados Python.csv', sep = ';', index = True, header=True)\n",
    "    time.sleep(10)\n",
    "    temp = pd.read_csv('999 '+ abrir +' - Dados Python.csv', sep = ';', usecols=[1])\n",
    "    xl.Quit() #fechar o Excel definitivamente\n",
    "    xl = None #fechar o Excel definitivamente\n",
    "    dados = pd.concat([dados,temp],axis=1).reindex(dados.index) #concatenar os DataFrame\n",
    "    n += 1\n",
    "\n",
    "dados.to_csv('999 Dados.csv', sep = ';', index = None, header = True)\n",
    "dados = pd.read_csv('999 Dados.csv', sep = ';', index_col = 0, header = 0)\n",
    "print (dados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c066c2",
   "metadata": {},
   "source": [
    "<h2 style = \"text-decoration: underline\">Primeiros cálculos do Portfolio</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae74eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETORNO PERCENTUAL DIARIO\n",
    "returns = dados.pct_change(fill_method='ffill')\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for c in returns.columns.values:\n",
    "    plt.plot(returns.index, returns[c], lw=3, alpha=0.8,label=c)\n",
    "plt.legend(loc='upper right', fontsize=8)\n",
    "plt.ylabel('daily returns')\n",
    "\n",
    "# Calculate the average daily return of the stock\n",
    "mean_return_daily = np.mean(returns)\n",
    "print (\"1. retorno médio diario em %: \", mean_return_daily*100)\n",
    "\n",
    "# Calculate the implied annualized average return\n",
    "mean_return_annualized = ((1+mean_return_daily)**252)-1\n",
    "print(\"2. retorno médio anualizado em %: \", mean_return_annualized*100)\n",
    "\n",
    "# Calculate the standard deviation of daily return of the stock\n",
    "sigma_daily = np.std(returns)\n",
    "print(\"3. volatilidade média diaria em %: \", sigma_daily*100)\n",
    "\n",
    "# Annualize the standard deviation\n",
    "sigma_annualized = sigma_daily*np.sqrt(252)\n",
    "print(\"4. volatilidade média anualizada em %: \", sigma_annualized*100)\n",
    "\n",
    "# Calculate the daily variance\n",
    "variance_daily = sigma_daily**2\n",
    "print(\"5. variância média diario em %: \", variance_daily*100)\n",
    "\n",
    "# Calculate the annualized variance\n",
    "variance_annualized = sigma_annualized**2\n",
    "print(\"6. variância média anualizado em %: \", variance_annualized)\n",
    "\n",
    "# Calculate the third moment (skewness) of the returns distribution\n",
    "returns_skewness = skew(returns.dropna())\n",
    "print(\"7. distribuição normal (skew ou assimetria): \", returns_skewness)\n",
    "\n",
    "# Calculate the excess kurtosis of the returns distribution\n",
    "excess_kurtosis = kurtosis(returns.dropna())\n",
    "print(\"8. distribuição normal (kurtosis ou kurtose): \", excess_kurtosis)\n",
    "\n",
    "# Derive the true fourth moment of the returns distribution\n",
    "fourth_moment = excess_kurtosis+3\n",
    "print(\"> real kurtosis: \", fourth_moment)#In SciPy the kurtosis function is actually computing excess kurtosis. \n",
    "                    #If you wanted to calculate the true sample kurtosis, you would actually need to add 3 to the result.\n",
    "    \n",
    "p_value = stats.shapiro(returns.dropna())[1]\n",
    "if p_value <= 0.05:\n",
    "    print(\"9. Teste de normalidade: \", p_value, \". Dados com distribuição não normal\")\n",
    "else:\n",
    "    print(\"9. Teste de normalidade: \", p_value, \". Dados com distribuição normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced0e6b",
   "metadata": {},
   "source": [
    "<h2 style = \"text-decoration: underline\">Cálculos para análise do Portfolio</h2>\n",
    "\n",
    "#O código dessa seção foi obtido e adaptado de: https://towardsdatascience.com/efficient-frontier-portfolio-optimisation-in-python-e7844051e7f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para construção dos Portfolio Automáticos e análises diversas\n",
    "np.random.seed(0)\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "corr_matrix=returns.corr()\n",
    "num_portfolios = 100000\n",
    "risk_free_rate = 0.1150\n",
    "\n",
    "corr_matrix.to_csv('993 CORRELAÇÃO.csv', sep = ';', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41687ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para construção dos Portfolio Automáticos e análises diversas\n",
    "np.random.seed(0)\n",
    "num_ativos = num_acoes + num_fundos\n",
    "num_ativos = int(num_ativos)\n",
    "#construção do retorno anualizado\n",
    "def portfolio_annualised_performance(weights, mean_returns, cov_matrix):\n",
    "    returns = np.sum(mean_returns*weights ) *252\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "    return std, returns\n",
    "\n",
    "#construção do portfolio aleatório\n",
    "def random_portfolios(num_portfolios, mean_returns, cov_matrix, risk_free_rate):\n",
    "    results = np.zeros((3,num_portfolios))\n",
    "    weights_record = []\n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(num_ativos)\n",
    "        weights /= np.sum(weights)\n",
    "        weights_record.append(weights)\n",
    "        portfolio_std_dev, portfolio_return = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "        results[0,i] = portfolio_std_dev\n",
    "        results[1,i] = portfolio_return\n",
    "        results[2,i] = (portfolio_return - risk_free_rate) / portfolio_std_dev\n",
    "    return results, weights_record\n",
    "\n",
    "#construção do portfolio sem ativos SHARPE negativo\n",
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    p_var, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_var\n",
    "\n",
    "#construção do portfolio de MAXIMO SHARPE sem ativos com SHARPE negativo\n",
    "def max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "#construção do retorno anualizado\n",
    "def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "    return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[0]\n",
    "\n",
    "#construção da VOLATILIDADE\n",
    "def min_variance(mean_returns, cov_matrix):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "#construção do Retorno Eficiente\n",
    "def efficient_return(mean_returns, cov_matrix, target):\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "\n",
    "    def portfolio_return(weights):\n",
    "        return portfolio_annualised_performance(weights, mean_returns, cov_matrix)[1]\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: portfolio_return(x) - target},\n",
    "                   {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for asset in range(num_assets))\n",
    "    result = sco.minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "#construção da FRONTEIRA EFICIENTE\n",
    "def efficient_frontier(mean_returns, cov_matrix, returns_range):\n",
    "    efficients = []\n",
    "    for ret in returns_range:\n",
    "        efficients.append(efficient_return(mean_returns, cov_matrix, ret))\n",
    "    return efficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate):\n",
    "    results, weights = random_portfolios(num_portfolios,mean_returns, cov_matrix, risk_free_rate)\n",
    "    \n",
    "    max_sharpe_idx = np.argmax(results[2])\n",
    "    sdp, rp = results[0,max_sharpe_idx], results[1,max_sharpe_idx]\n",
    "    max_sharpe_allocation = pd.DataFrame(weights[max_sharpe_idx],index=dados.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation.to_csv('991 MAX SHARPE.csv', sep = ';', index = True, header=True)\n",
    "    max_sharpe_allocation.to_csv('993 My PORTFOLIO.csv', sep = ';', index = True, header=True)\n",
    "    w1 = max_sharpe_allocation\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "        \n",
    "    min_vol_idx = np.argmin(results[0])\n",
    "    sdp_min, rp_min = results[0,min_vol_idx], results[1,min_vol_idx]\n",
    "    min_vol_allocation = pd.DataFrame(weights[min_vol_idx],index=dados.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation.to_csv('991 MIN VOLAT.csv', sep = ';', index = True, header=True)\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    an_vol = np.std(returns) * np.sqrt(252)\n",
    "    an_rt = mean_returns * 252\n",
    "    \n",
    "    print (\"-\"*80)\n",
    "    print (\"Maximum Sharpe Ratio Portfolio Aleatório\\n\")\n",
    "    print (\"Annualised Return:\", round(rp,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp,2))\n",
    "    print (\"\\n\")\n",
    "    print (max_sharpe_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Minimum Volatility Portfolio Aleatório\\n\")\n",
    "    print (\"Annualised Return:\", round(rp_min,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print (\"\\n\")\n",
    "    print (min_vol_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Individual Stock Returns and Volatility\\n\")\n",
    "    for i, txt in enumerate(dados.columns):\n",
    "        print (txt,\":\",\"annualised return\",round(an_rt[i],2),\", annualised volatility:\",round(an_vol[i],2))\n",
    "    print (\"-\"*80)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(results[0,:],results[1,:],c=results[2,:],cmap='YlGnBu', marker='o', s=10, alpha=0.3)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(sdp,rp,marker='*',color='r',s=300, label='Maximum Sharpe ratio')\n",
    "    plt.scatter(sdp_min,rp_min,marker='*',color='g',s=300, label='Minimum volatility')\n",
    "    plt.title('Simulated Portfolio Optimization based on Efficient Frontier')\n",
    "    plt.xlabel('annualised volatility')\n",
    "    plt.ylabel('annualised returns')\n",
    "    plt.legend(labelspacing=0.01)\n",
    "\n",
    "display_simulated_ef_with_random(mean_returns, cov_matrix, num_portfolios, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ef_with_selected(mean_returns, cov_matrix, risk_free_rate):\n",
    "    max_sharpe = max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate)\n",
    "    sdp, rp = portfolio_annualised_performance(max_sharpe['x'], mean_returns, cov_matrix)\n",
    "    max_sharpe_allocation = pd.DataFrame(max_sharpe.x,index=dados.columns,columns=['allocation'])\n",
    "    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n",
    "    max_sharpe_allocation.to_csv('992 MAX SHARPE.csv', sep = ';', index = True, header=True)\n",
    "    max_sharpe_allocation = max_sharpe_allocation.T\n",
    "\n",
    "    min_vol = min_variance(mean_returns, cov_matrix)\n",
    "    sdp_min, rp_min = portfolio_annualised_performance(min_vol['x'], mean_returns, cov_matrix)\n",
    "    min_vol_allocation = pd.DataFrame(min_vol.x,index=dados.columns,columns=['allocation'])\n",
    "    min_vol_allocation.allocation = [round(i*100,2)for i in min_vol_allocation.allocation]\n",
    "    min_vol_allocation.to_csv('992 MIN VOLAT.csv', sep = ';', index = True, header=True)\n",
    "    min_vol_allocation = min_vol_allocation.T\n",
    "    \n",
    "    an_vol = np.std(returns) * np.sqrt(252)\n",
    "    an_rt = mean_returns * 252\n",
    "    \n",
    "    print (\"-\"*80)\n",
    "    print (\"Maximum Sharpe Ratio Portfolio Selecionado\\n\")\n",
    "    print (\"Annualised Return:\", round(rp,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp,2))\n",
    "    print (\"\\n\")\n",
    "    print (max_sharpe_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Minimum Volatility Portfolio Selecionado\\n\")\n",
    "    print (\"Annualised Return:\", round(rp_min,2))\n",
    "    print (\"Annualised Volatility:\", round(sdp_min,2))\n",
    "    print (\"\\n\")\n",
    "    print (min_vol_allocation)\n",
    "    print (\"-\"*80)\n",
    "    print (\"Individual Stock Returns and Volatility\\n\")\n",
    "    for i, txt in enumerate(dados.columns):\n",
    "        print (txt,\":\",\"annualised return\",round(an_rt[i],2),\", annualised volatility:\",round(an_vol[i],2))\n",
    "    print (\"-\"*80)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    ax.scatter(an_vol,an_rt,marker='o',s=200)\n",
    "\n",
    "    for i, txt in enumerate(dados.columns):\n",
    "        ax.annotate(txt, (an_vol[i],an_rt[i]), xytext=(10,0), textcoords='offset points')\n",
    "        \n",
    "    ax.scatter(sdp,rp,marker='*',color='r',s=300, label='Maximum Sharpe ratio')\n",
    "    ax.scatter(sdp_min,rp_min,marker='*',color='g',s=300, label='Minimum volatility')\n",
    "    target = np.linspace(rp_min, 0.34, 50)\n",
    "    efficient_portfolios = efficient_frontier(mean_returns, cov_matrix, target)\n",
    "    ax.plot([p['fun'] for p in efficient_portfolios], target, linestyle='-.', color='black', label='efficient frontier')\n",
    "    ax.set_title('Portfolio Optimization with Individual Stocks')\n",
    "    ax.set_xlabel('annualised volatility')\n",
    "    ax.set_ylabel('annualised returns')\n",
    "    ax.legend(labelspacing=0)\n",
    "    \n",
    "display_ef_with_selected(mean_returns, cov_matrix, risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896e6bb",
   "metadata": {},
   "source": [
    "<h1 style = \"text-decoration: underline\">Cálculos de Análise de Portfolios e Value at Risk</h1>\n",
    "\n",
    "#O código dessa seção foi obtido e adaptado de: https://ebookreading.net/view/book/EB9781787125698_143.html e de: https://www.interviewqs.com/blog/value-at-risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0581d",
   "metadata": {},
   "source": [
    "<h3 style = \"text-decoration: underline\">Análise e Value at Risk PORTFOLIO ALEATÓRIO COM MAX SHARPE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1aa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the investment weights\n",
    "df = pd.read_csv('991 MAX SHARPE.csv', sep = ';', index_col = None)\n",
    "weights = df['allocation'].to_numpy()\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 100000\n",
    "\n",
    "# Retorno médio do portfolio\n",
    "port_mean = mean_returns.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    " \n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "             \n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "\n",
    "# Calculate Índice de Sharpe e Volatilidade anualizada\n",
    "isharpe = ((port_mean*252)-risk_free_rate)/(port_stdev*252)\n",
    "print(\"Índice de Sharpe: \", np.round(isharpe,2),\"\\n\")\n",
    "print(\"Volatilidade anualizada: \", np.round(port_stdev*np.sqrt(252), 0),\"%\\n\")\n",
    "\n",
    "# Select our confidence interval (I'll choose 95% here)\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio as calculated above\n",
    "\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "\n",
    "#Finally, we can calculate the VaR at our confidence interval\n",
    "VaR_1d = initial_investment - cutoff1\n",
    "\n",
    "# we will use return for average stock return of Portfolio\n",
    "sample_size = returns.shape[0]\n",
    "sample_mean = port_mean\n",
    "sample_std = port_stdev / sample_size**0.5\n",
    "\n",
    "# left and right quantile\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "# upper and lower bound\n",
    "interval_left = sample_mean + z_left * sample_std\n",
    "interval_right = sample_mean + z_right * sample_std\n",
    "\n",
    "# 95% confidence interval tells you that there will be 95% chance that the average stock return lies between \"interval_left\"\n",
    "# and \"interval_right\" em casos de distribuição normal, o que não se aplica a todos os casos.\n",
    "# De qualquer forma, o resultado apresentado, embora não se possa dizer que tenha um intervalo de confiança de 95%, nos dá uma\n",
    "# boa ilutração para análise do portfolio\n",
    "\n",
    "print('Intervalo esperado do retorno diário: ', np.round((interval_left, interval_right),3), '%\\n')\n",
    "\n",
    "print('Value at Risk Calculado para um dia: ',np.round((VaR_1d/initial_investment),3),'%\\n')\n",
    "\n",
    "#VaR Monte Carlo Simulation\n",
    "confidence = 0.95\n",
    "nSimulations = 100000\n",
    "sp.random.seed(0) \n",
    "ret2=sp.random.normal(port_mean,port_stdev,nSimulations) \n",
    "ret3=np.sort(ret2) \n",
    "m=int(nSimulations*(1-confidence))\n",
    "VaR2=initial_investment*(ret3[m])\n",
    "print (\"Value at Risk Calculado Sim. de Monte Carlo: \",np.round((VaR2/initial_investment)*-1,3),\"% \\n\")\n",
    "\n",
    "# Calculate n Day VaR\n",
    "var_array = []\n",
    "num_days = int(30)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(VaR_1d/initial_investment * np.sqrt(x),2))\n",
    "\n",
    "print(str(x) + \" day VaR Calculado: \" + str(np.round(VaR_1d/initial_investment * np.sqrt(x),2)),\"%\\n\")\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss esperado\")\n",
    "plt.title(\"Max portfolio loss esperado (VaR) over 30 days period\")\n",
    "plt.plot(var_array, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997517f7",
   "metadata": {},
   "source": [
    "<h3 style = \"text-decoration: underline\">Análise e Value at Risk PORTFOLIO ALEATÓRIO COM MIN VOLATILIDADE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e89865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the investment weights\n",
    "df = pd.read_csv('991 MIN VOLAT.csv', sep = ';', index_col = None)\n",
    "weights = df['allocation'].to_numpy()\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 100000\n",
    "\n",
    "# Retorno médio do portfolio\n",
    "port_mean = mean_returns.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    " \n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "             \n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "\n",
    "# Calculate Índice de Sharpe e Volatilidade anualizada\n",
    "isharpe = ((port_mean*252)-risk_free_rate)/(port_stdev*252)\n",
    "print(\"Índice de Sharpe: \", np.round(isharpe,2),\"\\n\")\n",
    "print(\"Volatilidade anualizada: \", np.round(port_stdev*np.sqrt(252), 0),\"%\\n\")\n",
    "\n",
    "# Select our confidence interval (I'll choose 95% here)\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio as calculated above\n",
    "\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "\n",
    "#Finally, we can calculate the VaR at our confidence interval\n",
    "VaR_1d = initial_investment - cutoff1\n",
    "\n",
    "# we will use return for average stock return of Portfolio\n",
    "sample_size = returns.shape[0]\n",
    "sample_mean = port_mean\n",
    "sample_std = port_stdev / sample_size**0.5\n",
    "\n",
    "# left and right quantile\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "# upper and lower bound\n",
    "interval_left = sample_mean + z_left * sample_std\n",
    "interval_right = sample_mean + z_right * sample_std\n",
    "\n",
    "# 95% confidence interval tells you that there will be 95% chance that the average stock return lies between \"interval_left\"\n",
    "# and \"interval_right\" em casos de distribuição normal, o que não se aplica a todos os casos.\n",
    "# De qualquer forma, o resultado apresentado, embora não se possa dizer que tenha um intervalo de confiança de 95%, nos dá uma\n",
    "# boa ilutração para análise do portfolio\n",
    "\n",
    "print('Intervalo esperado do retorno diário: ', np.round((interval_left, interval_right),3), '%\\n')\n",
    "\n",
    "print('Value at Risk Calculado para um dia: ',np.round((VaR_1d/initial_investment),3),'%\\n')\n",
    "\n",
    "#VaR Monte Carlo Simulation\n",
    "confidence = 0.95\n",
    "nSimulations = 100000\n",
    "sp.random.seed(0) \n",
    "ret2=sp.random.normal(port_mean,port_stdev,nSimulations) \n",
    "ret3=np.sort(ret2) \n",
    "m=int(nSimulations*(1-confidence))\n",
    "VaR2=initial_investment*(ret3[m])\n",
    "print (\"Value at Risk Calculado Sim. de Monte Carlo: \",np.round((VaR2/initial_investment)*-1,3),\"% \\n\")\n",
    "\n",
    "# Calculate n Day VaR\n",
    "var_array = []\n",
    "num_days = int(30)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(VaR_1d/initial_investment * np.sqrt(x),2))\n",
    "\n",
    "print(str(x) + \" day VaR Calculado: \" + str(np.round(VaR_1d/initial_investment * np.sqrt(x),2)),\"%\\n\")\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss esperado\")\n",
    "plt.title(\"Max portfolio loss esperado (VaR) over 30 days period\")\n",
    "plt.plot(var_array, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd085274",
   "metadata": {},
   "source": [
    "<h3 style = \"text-decoration: underline\">Análise e Value at Risk PORTFOLIO SELECIONADO PARA MAX SHARPE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bbe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the investment weights\n",
    "df = pd.read_csv('992 MAX SHARPE.csv', sep = ';', index_col = None)\n",
    "weights = df['allocation'].to_numpy()\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 100000\n",
    "\n",
    "# Retorno médio do portfolio\n",
    "port_mean = mean_returns.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    " \n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "             \n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "\n",
    "# Calculate Índice de Sharpe e Volatilidade anualizada\n",
    "isharpe = ((port_mean*252)-risk_free_rate)/(port_stdev*252)\n",
    "print(\"Índice de Sharpe: \", np.round(isharpe,2),\"\\n\")\n",
    "print(\"Volatilidade anualizada: \", np.round(port_stdev*np.sqrt(252), 0),\"%\\n\")\n",
    "\n",
    "# Select our confidence interval (I'll choose 95% here)\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio as calculated above\n",
    "\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "\n",
    "#Finally, we can calculate the VaR at our confidence interval\n",
    "VaR_1d = initial_investment - cutoff1\n",
    "\n",
    "# we will use return for average stock return of Portfolio\n",
    "sample_size = returns.shape[0]\n",
    "sample_mean = port_mean\n",
    "sample_std = port_stdev / sample_size**0.5\n",
    "\n",
    "# left and right quantile\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "# upper and lower bound\n",
    "interval_left = sample_mean + z_left * sample_std\n",
    "interval_right = sample_mean + z_right * sample_std\n",
    "\n",
    "# 95% confidence interval tells you that there will be 95% chance that the average stock return lies between \"interval_left\"\n",
    "# and \"interval_right\" em casos de distribuição normal, o que não se aplica a todos os casos.\n",
    "# De qualquer forma, o resultado apresentado, embora não se possa dizer que tenha um intervalo de confiança de 95%, nos dá uma\n",
    "# boa ilutração para análise do portfolio\n",
    "\n",
    "print('Intervalo esperado do retorno diário: ', np.round((interval_left, interval_right),3), '%\\n')\n",
    "\n",
    "print('Value at Risk Calculado para um dia: ',np.round((VaR_1d/initial_investment),3),'%\\n')\n",
    "\n",
    "#VaR Monte Carlo Simulation\n",
    "confidence = 0.95\n",
    "nSimulations = 100000\n",
    "sp.random.seed(0) \n",
    "ret2=sp.random.normal(port_mean,port_stdev,nSimulations) \n",
    "ret3=np.sort(ret2) \n",
    "m=int(nSimulations*(1-confidence))\n",
    "VaR2=initial_investment*(ret3[m])\n",
    "print (\"Value at Risk Calculado Sim. de Monte Carlo: \",np.round((VaR2/initial_investment)*-1,3),\"% \\n\")\n",
    "\n",
    "# Calculate n Day VaR\n",
    "var_array = []\n",
    "num_days = int(30)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(VaR_1d/initial_investment * np.sqrt(x),2))\n",
    "\n",
    "print(str(x) + \" day VaR Calculado: \" + str(np.round(VaR_1d/initial_investment * np.sqrt(x),2)),\"%\\n\")\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss esperado\")\n",
    "plt.title(\"Max portfolio loss esperado (VaR) over 30 days period\")\n",
    "plt.plot(var_array, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf720d",
   "metadata": {},
   "source": [
    "<h3 style = \"text-decoration: underline\">Análise e Value at Risk PORTFOLIO SELECIONADO PARA MIN VOLATILIDADE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7feb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the investment weights\n",
    "df = pd.read_csv('992 MIN VOLAT.csv', sep = ';', index_col = None)\n",
    "weights = df['allocation'].to_numpy()\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 100000\n",
    "\n",
    "# Retorno médio do portfolio\n",
    "port_mean = mean_returns.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    " \n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "             \n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "\n",
    "# Calculate Índice de Sharpe e Volatilidade anualizada\n",
    "isharpe = ((port_mean*252)-risk_free_rate)/(port_stdev*252)\n",
    "print(\"Índice de Sharpe: \", np.round(isharpe,2),\"\\n\")\n",
    "print(\"Volatilidade anualizada: \", np.round(port_stdev*np.sqrt(252), 0),\"%\\n\")\n",
    "\n",
    "# Select our confidence interval (I'll choose 95% here)\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio as calculated above\n",
    "\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "\n",
    "#Finally, we can calculate the VaR at our confidence interval\n",
    "VaR_1d = initial_investment - cutoff1\n",
    "\n",
    "# we will use return for average stock return of Portfolio\n",
    "sample_size = returns.shape[0]\n",
    "sample_mean = port_mean\n",
    "sample_std = port_stdev / sample_size**0.5\n",
    "\n",
    "# left and right quantile\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "# upper and lower bound\n",
    "interval_left = sample_mean + z_left * sample_std\n",
    "interval_right = sample_mean + z_right * sample_std\n",
    "\n",
    "# 95% confidence interval tells you that there will be 95% chance that the average stock return lies between \"interval_left\"\n",
    "# and \"interval_right\" em casos de distribuição normal, o que não se aplica a todos os casos.\n",
    "# De qualquer forma, o resultado apresentado, embora não se possa dizer que tenha um intervalo de confiança de 95%, nos dá uma\n",
    "# boa ilutração para análise do portfolio\n",
    "\n",
    "print('Intervalo esperado do retorno diário: ', np.round((interval_left, interval_right),3), '%\\n')\n",
    "\n",
    "print('Value at Risk Calculado para um dia: ',np.round((VaR_1d/initial_investment),3),'%\\n')\n",
    "\n",
    "#VaR Monte Carlo Simulation\n",
    "confidence = 0.95\n",
    "nSimulations = 100000\n",
    "sp.random.seed(0) \n",
    "ret2=sp.random.normal(port_mean,port_stdev,nSimulations) \n",
    "ret3=np.sort(ret2) \n",
    "m=int(nSimulations*(1-confidence))\n",
    "VaR2=initial_investment*(ret3[m])\n",
    "print (\"Value at Risk Calculado Sim. de Monte Carlo: \",np.round((VaR2/initial_investment)*-1,3),\"% \\n\")\n",
    "\n",
    "# Calculate n Day VaR\n",
    "var_array = []\n",
    "num_days = int(30)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(VaR_1d/initial_investment * np.sqrt(x),2))\n",
    "\n",
    "print(str(x) + \" day VaR Calculado: \" + str(np.round(VaR_1d/initial_investment * np.sqrt(x),2)),\"%\\n\")\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss esperado\")\n",
    "plt.title(\"Max portfolio loss esperado (VaR) over 30 days period\")\n",
    "plt.plot(var_array, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58e226",
   "metadata": {},
   "source": [
    "<h3 style = \"text-decoration: underline\">Análise e Value at Risk PORTFOLIO ELABORADO</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e115e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the investment weights na planilha MY PORTFOLIO, da forma que achar mais apropriado\n",
    "xl = win32com.client.DispatchEx(\"Excel.Application\")\n",
    "wb1 = xl.workbooks.open(r'...\\993 MY PORTFOLIO.csv')\n",
    "xl.visible = True\n",
    "continuar = 'N'\n",
    "continuar = input(\"O arquivo já está fechado para podermos continuar? (S/N)\")\n",
    "while continuar != 'S':\n",
    "    continuar = input(\"O arquivo já está fechado para podermos continuar? (S/N)\")\n",
    "xl.Quit() #fechar o Excel definitivamente\n",
    "xl = None #fechar o Excel definitivamente\n",
    "time.sleep(3)\n",
    "df = pd.read_csv('993 MY PORTFOLIO.csv', sep = ';', index_col = None)\n",
    "weights = df['allocation'].to_numpy()\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 100000\n",
    "\n",
    "# Retorno médio do portfolio\n",
    "port_mean = mean_returns.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    " \n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "             \n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "\n",
    "# Calculate Índice de Sharpe e Volatilidade anualizada\n",
    "isharpe = ((port_mean*252)-risk_free_rate)/(port_stdev*252)\n",
    "print(\"Índice de Sharpe: \", np.round(isharpe,2),\"\\n\")\n",
    "print(\"Volatilidade anualizada: \", np.round(port_stdev*np.sqrt(252), 0),\"%\\n\")\n",
    "\n",
    "# Select our confidence interval (I'll choose 95% here)\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio as calculated above\n",
    "\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "\n",
    "#Finally, we can calculate the VaR at our confidence interval\n",
    "VaR_1d = initial_investment - cutoff1\n",
    "\n",
    "# we will use return for average stock return of Portfolio\n",
    "sample_size = returns.shape[0]\n",
    "sample_mean = port_mean\n",
    "sample_std = port_stdev / sample_size**0.5\n",
    "\n",
    "# left and right quantile\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "# upper and lower bound\n",
    "interval_left = sample_mean + z_left * sample_std\n",
    "interval_right = sample_mean + z_right * sample_std\n",
    "\n",
    "# 95% confidence interval tells you that there will be 95% chance that the average stock return lies between \"interval_left\"\n",
    "# and \"interval_right\" em casos de distribuição normal, o que não se aplica a todos os casos.\n",
    "# De qualquer forma, o resultado apresentado, embora não se possa dizer que tenha um intervalo de confiança de 95%, nos dá uma\n",
    "# boa ilutração para análise do portfolio\n",
    "\n",
    "print('Intervalo esperado do retorno diário: ', np.round((interval_left, interval_right),3), '%\\n')\n",
    "\n",
    "print('Value at Risk Calculado para um dia: ',np.round((VaR_1d/initial_investment),3),'%\\n')\n",
    "\n",
    "#VaR Monte Carlo Simulation\n",
    "confidence = 0.95\n",
    "nSimulations = 100000\n",
    "sp.random.seed(0) \n",
    "ret2=sp.random.normal(port_mean,port_stdev,nSimulations) \n",
    "ret3=np.sort(ret2) \n",
    "m=int(nSimulations*(1-confidence))\n",
    "VaR2=initial_investment*(ret3[m])\n",
    "print (\"Value at Risk Calculado Sim. de Monte Carlo: \",np.round((VaR2/initial_investment)*-1,3),\"% \\n\")\n",
    "\n",
    "# Calculate n Day VaR\n",
    "var_array = []\n",
    "num_days = int(30)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(VaR_1d/initial_investment * np.sqrt(x),2))\n",
    "\n",
    "print(str(x) + \" day VaR Calculado: \" + str(np.round(VaR_1d/initial_investment * np.sqrt(x),2)),\"%\\n\")\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss esperado\")\n",
    "plt.title(\"Max portfolio loss esperado (VaR) over 30 days period\")\n",
    "plt.plot(var_array, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafdca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

